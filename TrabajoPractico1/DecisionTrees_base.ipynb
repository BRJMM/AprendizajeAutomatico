{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xqkkxFwaR6uO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1YOCBIryR6uR"
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "#dataset taken from https://www.kaggle.com/yashsawarn/wifi-stretgth-for-rooms\n",
        "\n",
        "USE_GINI = True\n",
        "\n",
        "def read_dataset(csv_name = 'wifi_localization.txt'):\n",
        "    \"\"\"\n",
        "    Reads a csv dataset\n",
        "    returns it as a pytorch tensor\n",
        "    \"\"\"\n",
        "    data_frame = pandas.read_table(csv_name, delim_whitespace=True, names=('A', 'B', 'C', 'D','E', 'F', 'G', 'ROOM'),\n",
        "                       dtype={'A': np.int64, 'B': np.float64, 'C': np.float64, 'D': np.float64,'E': np.float64,'F': np.float64,'G': np.float64,'ROOM': np.float64})\n",
        "\n",
        "    targets_torch = torch.tensor(data_frame['ROOM'].values)\n",
        "    dataset_torch = torch.tensor(data_frame.values)\n",
        "\n",
        "    return dataset_torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Implementaci칩n de la clasificaci칩n multi-clase con 치rboles de decisi칩n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EZ8GFkT5R6uS"
      },
      "outputs": [],
      "source": [
        "class Node_CART:\n",
        "    def __init__(self, num_classes = 4, ref_CART = None, current_depth = 0):\n",
        "        \"\"\"\n",
        "        Create the node attributes\n",
        "        param num_classes: K number of classes to classify\n",
        "        param ref_cart: reference to the tree containing the node\n",
        "        param current_depth: current depth of the node in the tree\n",
        "        \"\"\"\n",
        "        self.ref_CART = ref_CART\n",
        "        self.threshold_value = 0\n",
        "        self.feature_num = 0\n",
        "        self.node_right = None\n",
        "        self.node_left = None\n",
        "        self.data_torch_partition = None\n",
        "        self.gini = 0\n",
        "        self.dominant_class = None\n",
        "        self.accuracy_dominant_class = None\n",
        "        self.num_classes = num_classes\n",
        "        self.current_depth = current_depth\n",
        "\n",
        "    def to_xml(self, current_str = \"\"):\n",
        "        \"\"\"\n",
        "        Recursive function to write the node content to an xml formatted string\n",
        "        param current_str : the xml content so far in the whole tree\n",
        "        return the string with the node content\n",
        "        \"\"\"\n",
        "        str_node = \"<node><thresh>\" + str(self.threshold_value) + \"</thresh>\" + \"<feature>\" + str(self.feature_num) + \"</feature><depth>\" + str(self.current_depth)+ \"</depth>\"\n",
        "        str_node += \"<gini>\" + str(self.gini) + \"</gini>\"\n",
        "        if(self.node_right != None):\n",
        "            str_left = self.node_right.to_xml(current_str)\n",
        "            str_node += str_left\n",
        "        if(self.node_left != None):\n",
        "            str_right = self.node_left.to_xml(current_str)\n",
        "            str_node += str_right\n",
        "\n",
        "        if(self.is_leaf()):\n",
        "            str_node += \"<dominant_class>\" + str(self.dominant_class) + \"</dominant_class><acc_dominant_class>\"  + str(self.accuracy_dominant_class) + \"</acc_dominant_class>\"\n",
        "        str_node += \"</node>\"\n",
        "        return str_node\n",
        "\n",
        "    def is_leaf(self):\n",
        "        \"\"\"\n",
        "        Checks whether the node is a leaf\n",
        "        \"\"\"\n",
        "        return (self.node_left == None and self.node_right == None)\n",
        "\n",
        "    def create_with_children(self, data_torch, current_depth, list_selected_features = [], min_gini = 0.000001):\n",
        "        \"\"\"\n",
        "        Creates a node by selecting the best feature and threshold, and if needed, creating its children\n",
        "        param data_torch: dataset with the current partition to deal with in the node\n",
        "        param current_depth: depth counter for the node\n",
        "        param list_selected_features: list of selected features so far for the CART building process\n",
        "        param min_gini: hyperparmeter selected by the user defining the minimum tolerated gini coefficient for a  node\n",
        "        return the list of selected features so far\n",
        "        \"\"\"\n",
        "        self.data_torch_partition = data_torch\n",
        "        self.threshold_value, self.feature_num, self.gini = self.select_best_feature_and_thresh(data_torch, list_selected_features)\n",
        "        # if not at max depth\n",
        "        self.gini = self.calculate_gini(data_torch)\n",
        "        if current_depth < self.ref_CART.max_CART_depth and self.gini >= min_gini:\n",
        "            # if we found an appropiate feature + threshold\n",
        "            if self.feature_num != float('inf') and self.threshold_value != float('inf'):\n",
        "                left_data_torch = data_torch[data_torch[:,self.feature_num] <= self.threshold_value]\n",
        "                right_data_torch = data_torch[data_torch[:,self.feature_num] > self.threshold_value]\n",
        "                min_obs_per_leaf = self.ref_CART.get_min_observations()\n",
        "                if (left_data_torch.shape[0] >= min_obs_per_leaf and right_data_torch.shape[0] >= min_obs_per_leaf):\n",
        "                    list_selected_features.append(self.feature_num)\n",
        "                    # lefts\n",
        "                    self.node_left = Node_CART(ref_CART=self.ref_CART, current_depth=current_depth+1)\n",
        "                    list_selected_features_left = self.node_left.create_with_children(left_data_torch, (current_depth+1), list_selected_features, min_gini)\n",
        "                    # right\n",
        "                    self.node_right = Node_CART(ref_CART=self.ref_CART, current_depth=current_depth+1)\n",
        "                    list_selected_features_right = self.node_right.create_with_children(right_data_torch, (current_depth+1), list_selected_features, min_gini)\n",
        "                    # combinar listas\n",
        "                    list_selected_features = list(set(list_selected_features_left + list_selected_features_right))\n",
        "        # dominant class\n",
        "        labels, counts = torch.unique(data_torch[:,-1], return_counts=True)\n",
        "        dominant_index = torch.argmax(counts)\n",
        "        dominant_class = labels[dominant_index].item()\n",
        "        self.dominant_class = dominant_class\n",
        "        return list_selected_features\n",
        "\n",
        "    def calculate_gini(self, data_partition_torch: torch.tensor, num_classes: int = 4):\n",
        "        \"\"\"\n",
        "        Calculates the gini coefficient for a given partition with the given number of classes\n",
        "        param data_partition_torch: current dataset partition as a tensor\n",
        "        param num_classes: K number of classes to discriminate from\n",
        "        returns the calculated gini coefficient\n",
        "        \"\"\"\n",
        "        ROOM_COLUMN_INDEX = 7\n",
        "        class_counts = torch.bincount(data_partition_torch[:, -1], minlength=num_classes + 1)\n",
        "        class_counts = class_counts[1:]\n",
        "        class_probabilities = class_counts.float() / data_partition_torch.shape[0]\n",
        "        gini_coef = 1.0 - torch.sum(class_probabilities ** 2)\n",
        "        return gini_coef\n",
        "\n",
        "    def calculate_entropy(self, data_partition_torch, num_classes = 4):\n",
        "        \"\"\"\n",
        "        Calculates the entropy for a given partition with the given number of classes\n",
        "        param data_partition_torch: current dataset partition as a tensor\n",
        "        param num_classes: K number of classes to discriminate from\n",
        "        returns the calculated entropy\n",
        "        \"\"\"\n",
        "        ROOM_COLUMN_INDEX = 7\n",
        "        class_counts = torch.bincount(data_partition_torch[:, -1], minlength=num_classes + 1)\n",
        "        class_counts = class_counts[1:]\n",
        "        p_k = class_counts.float() / data_partition_torch.shape[0]\n",
        "        p_k[p_k == 0.0] = 1.0 # Remove 0 value, since log2(0) = -inf and log2(1) = 0\n",
        "        return -1*torch.sum(p_k*torch.log2(p_k))\n",
        "\n",
        "    def evaluate_node(self, input_torch):\n",
        "        \"\"\"\n",
        "        Evaluates an input observation within the node.\n",
        "        If is not a leaf node, send it to the corresponding node\n",
        "        return predicted label\n",
        "        \"\"\"\n",
        "        feature_val_input = input_torch[self.feature_num]\n",
        "        if(self.is_leaf()):\n",
        "            return self.dominant_class\n",
        "        else:\n",
        "            if(feature_val_input <= self.threshold_value):\n",
        "                return self.node_left.evaluate_node(input_torch)\n",
        "            else:\n",
        "                return self.node_right.evaluate_node(input_torch)\n",
        "\n",
        "    def evaluate_optimal_loss(self, right_data_partition: torch.tensor,\n",
        "                              left_data_partition: torch.tensor,\n",
        "                              n_data_partition: int,\n",
        "                              num_classes: int,\n",
        "                              error_func):\n",
        "        \n",
        "        return (right_data_partition.shape[0]/n_data_partition) * error_func(right_data_partition, num_classes).item() + \\\n",
        "                (left_data_partition.shape[0]/n_data_partition) * error_func(left_data_partition, num_classes).item()\n",
        "\n",
        "    def select_best_feature_and_thresh(self, data_torch, list_features_selected = [], num_classes = 4):\n",
        "        \"\"\"\n",
        "        Selects the best feature and threshold that minimizes the gini coefficient\n",
        "        param data_torch: dataset partition to analyze\n",
        "        param list_features_selected list of features selected so far, thus must be ignored\n",
        "        param num_classes: number of K classes to discriminate from\n",
        "        return min_thresh, min_feature, min_gini found for the dataset partition when\n",
        "        selecting the found feature and threshold\n",
        "        \"\"\"\n",
        "\n",
        "        min_thresh = float('inf')\n",
        "        min_feature = 0\n",
        "        min_gini = float('inf')\n",
        "\n",
        "        total_data_torch = data_torch.shape[1]\n",
        "\n",
        "        # -1 to ignore label\n",
        "        for feature in range(total_data_torch - 1):\n",
        "          if (feature not in list_features_selected):\n",
        "            for threshold in data_torch[:, feature]:\n",
        "                left_data = data_torch[data_torch[:,feature] <= threshold]\n",
        "                right_data = data_torch[data_torch[:,feature] > threshold]\n",
        "                # solution to avoid division by 0 in calculate_gini in case a partition has 0 elements\n",
        "                if (left_data.shape[0] > 0 and right_data.shape[0] > 0):\n",
        "                    if USE_GINI:\n",
        "                        weighted_err = self.evaluate_optimal_loss(right_data, left_data, total_data_torch, num_classes, self.calculate_gini)\n",
        "                    else:\n",
        "                        weighted_err = self.evaluate_optimal_loss(right_data, left_data, total_data_torch, num_classes, self.calculate_entropy)\n",
        "                    if (weighted_err < min_gini):\n",
        "                        min_thresh = threshold\n",
        "                        min_feature = feature\n",
        "                        min_gini = weighted_err\n",
        "        return (min_thresh, min_feature, min_gini)\n",
        "\n",
        "\n",
        "class CART:\n",
        "    def __init__(self, dataset_torch, max_CART_depth, min_observations = 2):\n",
        "        \"\"\"\n",
        "        CART has only one root node\n",
        "        \"\"\"\n",
        "        #min observations per node\n",
        "        self.min_observations = min_observations\n",
        "        self.list_selected_features = []\n",
        "        self.root = Node_CART(num_classes = 4, ref_CART = self, current_depth = 0)\n",
        "        self.max_CART_depth = max_CART_depth\n",
        "        print(self.list_selected_features)\n",
        "        \n",
        "\n",
        "    def get_root(self):\n",
        "        \"\"\"\n",
        "        Gets tree root\n",
        "        \"\"\"\n",
        "        return self.root\n",
        "\n",
        "    def get_min_observations(self):\n",
        "        \"\"\"\n",
        "        return min observations per node\n",
        "        \"\"\"\n",
        "        return self.min_observations\n",
        "\n",
        "    def get_max_depth(self):\n",
        "        \"\"\"\n",
        "        Gets the selected max depth of the tree\n",
        "        \"\"\"\n",
        "        return self.max_CART_depth\n",
        "\n",
        "    def build_CART(self, data_torch):\n",
        "        \"\"\"\n",
        "        Build CART from root\n",
        "        \"\"\"\n",
        "        self.list_selected_features = self.root.create_with_children(data_torch, current_depth = 0, list_selected_features=self.list_selected_features)\n",
        "\n",
        "    def to_xml(self, xml_file_name):\n",
        "        \"\"\"\n",
        "        write Xml file with tree content\n",
        "        \"\"\"\n",
        "        str_nodes = self.root.to_xml()\n",
        "        file = open(xml_file_name,\"w+\")\n",
        "        file.write(str_nodes)\n",
        "        file.close()\n",
        "        return str_nodes\n",
        "\n",
        "    def evaluate_input(self, input_torch):\n",
        "        \"\"\"\n",
        "        Evaluate a specific input in the tree and get the predicted class\n",
        "        \"\"\"\n",
        "        return self.root.evaluate_node(input_torch)\n",
        "\n",
        "def train_CART(dataset_torch, name_xml = \"\", max_CART_depth = 3, min_obs_per_leaf = 2):\n",
        "    \"\"\"\n",
        "    Train CART model\n",
        "    \"\"\"\n",
        "    tree = CART(dataset_torch = dataset_torch, max_CART_depth = max_CART_depth, min_observations =  min_obs_per_leaf)\n",
        "    tree.build_CART(dataset_torch)\n",
        "    if(not name_xml == \"\"):\n",
        "        tree.to_xml(name_xml)\n",
        "    return tree\n",
        "\n",
        "def test_CART(tree, testset_torch):\n",
        "    \"\"\"\n",
        "    Test a previously built CART\n",
        "    \"\"\"\n",
        "    #ROOM_COLUMN_INDEX = 7\n",
        "    ROOM_COLUMN_INDEX = -1\n",
        "    class_columns = testset_torch[:, -1].int()\n",
        "    num_classes = torch.bincount(class_columns)[1:].shape[0]\n",
        "    n = testset_torch.shape[0]\n",
        "    predicted_values = []\n",
        "    c = 0\n",
        "    for current_observation in testset_torch:\n",
        "        real_value = current_observation[ROOM_COLUMN_INDEX].item()\n",
        "        predicted_value = tree.evaluate_input(current_observation)\n",
        "        predicted_values.append(predicted_value)\n",
        "        c = c+1 if predicted_value == real_value else c\n",
        "        #print('predicted_value=[{}], num_classes=[{}], real_value=[{}]'.format(predicted_value, num_classes, real_value))\n",
        "    return c/n, predicted_values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZDmgW8mR6uT"
      },
      "source": [
        "## Gini Unit Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQfzXD_TR6uU",
        "outputId": "efbda156-9342-42f6-d936-48dfcf733949"
      },
      "outputs": [],
      "source": [
        "import unittest\n",
        "\n",
        "class GiniUnitTest(unittest.TestCase):\n",
        "\n",
        "    def test_singleClassOneData(self):\n",
        "      data = torch.tensor([[-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t1]])\n",
        "      node = Node_CART()\n",
        "      gini_result = node.calculate_gini(data, num_classes=1)\n",
        "      self.assertTrue(torch.equal(gini_result, torch.tensor(0.0)))\n",
        "\n",
        "    def test_twoClassesOneDataPerClass(self):\n",
        "      data = torch.tensor([[-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t1], [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t2]])\n",
        "      node = Node_CART()\n",
        "      gini_result = node.calculate_gini(data, num_classes=2)\n",
        "      self.assertTrue(torch.equal(gini_result, torch.tensor(0.5)))\n",
        "\n",
        "    def test_twoClassesOnlyOneClassWithData(self):\n",
        "      data = torch.tensor([[-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t1], [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t1]])\n",
        "      node = Node_CART()\n",
        "      gini_result = node.calculate_gini(data, num_classes=2)\n",
        "      self.assertTrue(torch.equal(gini_result, torch.tensor(0.0)))\n",
        "\n",
        "    def test_fourClassesOneDataPerClass(self):\n",
        "      data = torch.tensor([[-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t1], [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t2], [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t3], [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t4]])\n",
        "      node = Node_CART()\n",
        "      gini_result = node.calculate_gini(data, num_classes=4)\n",
        "      self.assertTrue(torch.equal(gini_result, torch.tensor(0.75)))\n",
        "\n",
        "    def test_fourClassesOnlyTwoClassesWithData(self):\n",
        "      data = torch.tensor([[-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t1], [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t1], [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t4], [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t4]])\n",
        "      node = Node_CART()\n",
        "      gini_result = node.calculate_gini(data, num_classes=4)\n",
        "      self.assertTrue(torch.equal(gini_result, torch.tensor(0.5)))\n",
        "\n",
        "    def test_fourClassesOnlyThreeClassesWithData(self):\n",
        "      data = torch.tensor([[-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t1], [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t1], [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t3], [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t4]])\n",
        "      node = Node_CART()\n",
        "      gini_result = node.calculate_gini(data, num_classes=4)\n",
        "      self.assertTrue(torch.equal(gini_result, torch.tensor(0.625)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e49nDiY_VPKs"
      },
      "source": [
        "## Entropy Unit Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-o61zW_bVOCh",
        "outputId": "b0036ddc-9346-4517-c139-4a655e25f157"
      },
      "outputs": [],
      "source": [
        "class EntropyUnitTest(unittest.TestCase):\n",
        "    def test_twoClasses5and9(self):\n",
        "      data = torch.tensor([\n",
        "        [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t1],\n",
        "        [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t1],\n",
        "        [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t1],\n",
        "        [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t1],\n",
        "        [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t1],\n",
        "        [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t2],\n",
        "        [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t2],\n",
        "        [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t2],\n",
        "        [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t2],\n",
        "        [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t2],\n",
        "        [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t2],\n",
        "        [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t2],\n",
        "        [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t2],\n",
        "        [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t2]\n",
        "      ])\n",
        "      node = Node_CART()\n",
        "      entropy_result = node.calculate_entropy(data, num_classes=2)\n",
        "      self.assertAlmostEqual(entropy_result.item(), 0.94, delta=0.01)\n",
        "\n",
        "    def test_twoClassesEqualItems(self):\n",
        "      data = torch.tensor([\n",
        "        [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t1],\n",
        "        [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t1],\n",
        "        [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t2],\n",
        "        [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t2]\n",
        "      ])\n",
        "      node = Node_CART()\n",
        "      entropy_result = node.calculate_entropy(data, num_classes=2)\n",
        "      self.assertAlmostEqual(entropy_result.item(), 1.0, delta=0.01)\n",
        "\n",
        "    def test_twoClassesAllItemsOneClass(self):\n",
        "      data = torch.tensor([\n",
        "        [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t1],\n",
        "        [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t1],\n",
        "        [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t1],\n",
        "        [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t1]\n",
        "      ])\n",
        "      node = Node_CART()\n",
        "      entropy_result = node.calculate_entropy(data, num_classes=2)\n",
        "      self.assertAlmostEqual(entropy_result.item(), 0.0, delta=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRWjEzAGOQUn"
      },
      "source": [
        "## Feat and Thresh Selection Unit test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g76Z6KvONS8A",
        "outputId": "b44cb6c4-83d8-43a4-9fa5-6d5b38248c55"
      },
      "outputs": [],
      "source": [
        "class BestFeatAndThreshUnitTest(unittest.TestCase):\n",
        "\n",
        "    def test_optimal_gini(self):\n",
        "      right_data = torch.tensor([[-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t1], [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t2], [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t3], [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t4]])\n",
        "      left_data = torch.tensor([[-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t1], [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t1], [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t3], [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,\t4]])\n",
        "      node = Node_CART()\n",
        "      result = node.evaluate_optimal_loss(right_data, left_data, n_data_partition=8, num_classes=4, error_func=node.calculate_gini)\n",
        "      self.assertEqual(result, 0.6875)\n",
        "\n",
        "    def test_twoClassesTwoElementsPerClassGini(self):\n",
        "      global USE_GINI\n",
        "      USE_GINI = True\n",
        "      data = torch.tensor([ [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,  1],\n",
        "                            [-50, -14,\t-1,\t-90,\t-100,\t-80,\t-84,\t2],\n",
        "                            [-25, -50,\t-100,\t-9,\t-10,\t-85,\t-70,\t2],\n",
        "                            [-64, -56,\t-61,\t-66,\t-71,\t-82,\t-81,  1]])\n",
        "      node = Node_CART()\n",
        "      ((min_thresh, min_feature, min_gini)) = node.select_best_feature_and_thresh(data, num_classes=2)\n",
        "      self.assertEqual(min_thresh, torch.tensor(-64))\n",
        "      self.assertEqual(min_feature, torch.tensor(0.0))\n",
        "      self.assertEqual(min_gini, torch.tensor(0.0))\n",
        "\n",
        "    def test_twoClassesTwoElementsPerClassEntropy(self):\n",
        "      global USE_GINI\n",
        "      USE_GINI = False\n",
        "      data = torch.tensor([ [1, 1, 1,\t1, 1,\t1, 1,\t1],\n",
        "                            [1, 1, 0,\t1, 1,\t1, 1,\t1],\n",
        "                            [1, 1, 1,\t1, 1,\t1, 1,\t2],\n",
        "                            [1, 1, 1,\t1, 1,\t1, 1,\t2]])\n",
        "      node = Node_CART()\n",
        "      ((min_thresh, min_feature, min_gini)) = node.select_best_feature_and_thresh(data, num_classes=2)\n",
        "      self.assertEqual(min_thresh, torch.tensor(0.))\n",
        "      self.assertEqual(min_feature, torch.tensor(2))\n",
        "      self.assertEqual(min_gini, torch.tensor(0.34436094760894775))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create with Children Unit test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CreateWithChildrenUnitTest(unittest.TestCase):\n",
        "    def test_twoClassesTwoDataPerClass(self):\n",
        "      data = torch.tensor([ [-64, -56,\t-61,\t-90,\t-71,\t-82,\t-81,  1],\n",
        "                            [-64, -14,\t-61,\t-90,\t-71,\t-82,\t-81,  2],\n",
        "                            [-64, -56,\t-61,\t-90,\t-71,\t-82,\t-81,  2],\n",
        "                            [-64, -56,\t-60,\t-90,\t-71,\t-82,\t-81,  1]])\n",
        "      cart = CART(data, 2, 1)\n",
        "      cart.build_CART(data)\n",
        "      self.assertEqual(cart.list_selected_features, [1, 2])\n",
        "\n",
        "    def test_twoClassesTwoDataPerClass_depth(self):\n",
        "      data = torch.tensor([ [-64, -56,\t-61,\t-90,\t-71,\t-82,\t-81,  1],\n",
        "                            [-64, -14,\t-61,\t-90,\t-71,\t-82,\t-81,  2],\n",
        "                            [-64, -56,\t-61,\t-90,\t-71,\t-82,\t-81,  2],\n",
        "                            [-64, -56,\t-60,\t-90,\t-71,\t-82,\t-81,  1]])\n",
        "      cart = CART(data, 1, 1)\n",
        "      cart.build_CART(data)\n",
        "      self.assertEqual(cart.list_selected_features, [1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## test_CART Unit Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TestCARTUnitTest(unittest.TestCase):\n",
        "\n",
        "    def test_cartWithTwoClassesRightPrediction(self):\n",
        "      train_data = torch.tensor([[0, 1, 0,\t1, 1,\t1, 1,\t1],\n",
        "                                 [0, 0, 1,\t1, 1,\t1, 1,\t2]])\n",
        "\n",
        "      test_tree = train_CART(train_data, min_obs_per_leaf=1)\n",
        "      test_data = torch.tensor([[1, 1, 0,\t1, 1,\t0, 1,\t1],\n",
        "                                [1, 0, 1,\t1, 1,\t1, 0,\t2]])\n",
        "      acc, predicted_values = test_CART(test_tree, test_data)\n",
        "      self.assertEqual(acc, 1.0)\n",
        "      self.assertEqual(predicted_values, [1, 2])\n",
        "\n",
        "\n",
        "    def test_cartWithTwoClassesWrongTestLabel(self):\n",
        "      train_data = torch.tensor([[0, 1, 0,\t1, 1,\t1, 1,\t1],\n",
        "                                 [0, 0, 1,\t1, 1,\t1, 1,\t2]])\n",
        "\n",
        "      test_tree = train_CART(train_data, min_obs_per_leaf=1)\n",
        "      test_data = torch.tensor([[1, 1, 0,\t1, 1,\t0, 1,\t1],\n",
        "                                [1, 0, 1,\t1, 1,\t1, 0,\t1]])\n",
        "      acc, predicted_values = test_CART(test_tree, test_data)\n",
        "      self.assertEqual(acc, 0.5)\n",
        "      self.assertEqual(predicted_values, [1, 2])\n",
        "\n",
        "\n",
        "    def test_cartWithFourClassesRightPrediction(self):\n",
        "      train_data = torch.tensor([[0, 1, 1, 1, 1, 1, 1, 1],\n",
        "                                 [1, 0, 1, 1, 1, 1, 1, 2],\n",
        "                                 [1, 1, 0, 1, 1, 1, 1, 3],\n",
        "                                 [1, 1, 1, 0, 1, 1, 1, 4]])\n",
        "      test_tree = train_CART(train_data, max_CART_depth=5, min_obs_per_leaf=1)\n",
        "      test_data = torch.tensor([[1, 0, 1,\t1, 1,\t1, 0,\t2],\n",
        "                                [1, 1, 1,\t0, 1,\t0, 1,\t4]])\n",
        "      test_tree.to_xml(\"michael.xml\")\n",
        "      acc, predicted_values = test_CART(test_tree, test_data)\n",
        "      self.assertEqual(acc, 1.0)\n",
        "      self.assertEqual(predicted_values, [2, 4])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ejecuci칩n Unit Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "test_optimal_gini (__main__.BestFeatAndThreshUnitTest.test_optimal_gini) ... ok\n",
            "test_twoClassesTwoElementsPerClassEntropy (__main__.BestFeatAndThreshUnitTest.test_twoClassesTwoElementsPerClassEntropy) ... ok\n",
            "test_twoClassesTwoElementsPerClassGini (__main__.BestFeatAndThreshUnitTest.test_twoClassesTwoElementsPerClassGini) ... ok\n",
            "test_twoClassesTwoDataPerClass (__main__.CreateWithChildrenUnitTest.test_twoClassesTwoDataPerClass) ... ok\n",
            "test_twoClassesTwoDataPerClass_depth (__main__.CreateWithChildrenUnitTest.test_twoClassesTwoDataPerClass_depth) ... ok\n",
            "test_twoClasses5and9 (__main__.EntropyUnitTest.test_twoClasses5and9) ... ok\n",
            "test_twoClassesAllItemsOneClass (__main__.EntropyUnitTest.test_twoClassesAllItemsOneClass) ... ok\n",
            "test_twoClassesEqualItems (__main__.EntropyUnitTest.test_twoClassesEqualItems) ... ok\n",
            "test_fourClassesOneDataPerClass (__main__.GiniUnitTest.test_fourClassesOneDataPerClass) ... ok\n",
            "test_fourClassesOnlyThreeClassesWithData (__main__.GiniUnitTest.test_fourClassesOnlyThreeClassesWithData) ... ok\n",
            "test_fourClassesOnlyTwoClassesWithData (__main__.GiniUnitTest.test_fourClassesOnlyTwoClassesWithData) ... ok\n",
            "test_singleClassOneData (__main__.GiniUnitTest.test_singleClassOneData) ... ok\n",
            "test_twoClassesOneDataPerClass (__main__.GiniUnitTest.test_twoClassesOneDataPerClass) ... ok\n",
            "test_twoClassesOnlyOneClassWithData (__main__.GiniUnitTest.test_twoClassesOnlyOneClassWithData) ... ok\n",
            "test_cartWithFourClassesRightPrediction (__main__.TestCARTUnitTest.test_cartWithFourClassesRightPrediction) ... ok\n",
            "test_cartWithTwoClassesRightPrediction (__main__.TestCARTUnitTest.test_cartWithTwoClassesRightPrediction) ... ok\n",
            "test_cartWithTwoClassesWrongTestLabel (__main__.TestCARTUnitTest.test_cartWithTwoClassesWrongTestLabel) ... ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 17 tests in 0.082s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<unittest.main.TestProgram at 0x1a8d2788f50>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "unittest.main(argv=[''], verbosity=2, exit=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluaci칩n del CART"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def f1_score(input, target, epsilon = 1e-7):\n",
        "    input = torch.tensor(input)\n",
        "    target = torch.tensor(target)\n",
        "    \n",
        "    class_f1_scores = []\n",
        "    for class_label in torch.unique(target):\n",
        "        # true positives, false positives, and false negatives for the current class\n",
        "        tp = torch.sum((input == class_label) & (target == class_label)).float()\n",
        "        fp = torch.sum((input == class_label) & (target != class_label)).float()\n",
        "        fn = torch.sum((input != class_label) & (target == class_label)).float()\n",
        "\n",
        "        # precision and recall for the current class\n",
        "        precision = tp / (tp + fp + epsilon)\n",
        "        recall = tp / (tp + fn + epsilon)\n",
        "\n",
        "        # Compute F1 score for the current class\n",
        "        class_f1 = 2 * (precision * recall) / (precision + recall + epsilon)\n",
        "        class_weight = torch.sum(target == class_label).float()\n",
        "        class_f1_scores.append(class_f1 * class_weight)\n",
        "\n",
        "    weighted_f1 = torch.sum(torch.tensor(class_f1_scores)) / torch.numel(target)\n",
        "    return weighted_f1\n",
        "\n",
        "def train_test_split(X_data, train_size=0.7): \n",
        "    rand_indices = torch.randperm(X_data.shape[0]) \n",
        " \n",
        "    # get split sizes \n",
        "    train_split = int(train_size * rand_indices.shape[0]) \n",
        "    test_split = rand_indices.shape[0] - train_split \n",
        " \n",
        "    # split data \n",
        "    train_split = X_data[rand_indices[:train_split]] \n",
        "    test_split = X_data[rand_indices[test_split:]] \n",
        " \n",
        "    # Split to follow scikit learns format. \n",
        "    X_train = train_split[:,:-1] \n",
        "    y_train = train_split[:,-1] \n",
        "    X_test = test_split[:,:-1] \n",
        "    y_test = test_split[:,-1] \n",
        "    return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset_torch = [\n",
            "tensor([[-64, -56, -61,  ..., -82, -81,   1],\n",
            "        [-68, -57, -61,  ..., -85, -85,   1],\n",
            "        [-63, -60, -60,  ..., -85, -84,   1],\n",
            "        ...,\n",
            "        [-62, -59, -46,  ..., -87, -88,   4],\n",
            "        [-62, -58, -52,  ..., -90, -85,   4],\n",
            "        [-59, -50, -45,  ..., -88, -87,   4]], dtype=torch.int32)\n",
            "]\n",
            "[GINI] - Test CART with max_CART_depth=[3] and min_obs_per_leaf=[2]\n",
            "[]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\pavel\\AppData\\Local\\Temp\\ipykernel_31488\\3724860516.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  input = torch.tensor(input)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[GINI] - Accuracy rate=[0.9355], f1_score=[0.9356065392494202]\n",
            "[GINI] - Test CART with max_CART_depth=[4] and min_obs_per_leaf=[2]\n",
            "[]\n",
            "[GINI] - Accuracy rate=[0.7515], f1_score=[0.8289557695388794]\n",
            "[ENTROPY] - Test CART with max_CART_depth=[3] and min_obs_per_leaf=[2]\n",
            "[]\n",
            "[ENTROPY] - Accuracy rate=[0.9445], f1_score=[0.9445338249206543]\n",
            "[ENTROPY] - Test CART with max_CART_depth=[4] and min_obs_per_leaf=[2]\n",
            "[]\n",
            "[ENTROPY] - Accuracy rate=[0.751], f1_score=[0.8284593224525452]\n"
          ]
        }
      ],
      "source": [
        "dataset_torch = read_dataset().int()\n",
        "print('dataset_torch = [\\n{}\\n]'.format(dataset_torch))\n",
        "\n",
        "############################### USING GINI ################################\n",
        "USE_GINI = True\n",
        "\n",
        "print('[GINI] - Test CART with max_CART_depth=[3] and min_obs_per_leaf=[2]')\n",
        "tree_3 = train_CART(dataset_torch, name_xml = \"CART_example.xml\", max_CART_depth=3, min_obs_per_leaf=2)\n",
        "acc, predicted_values = test_CART(tree_3, dataset_torch)\n",
        "f1 = f1_score(dataset_torch[:,-1], predicted_values) \n",
        "\n",
        "print(f'[GINI] - Accuracy rate=[{acc}], f1_score=[{f1}]')\n",
        "\n",
        "#########\n",
        "\n",
        "print('[GINI] - Test CART with max_CART_depth=[4] and min_obs_per_leaf=[2]')\n",
        "tree_4 = train_CART(dataset_torch, name_xml = \"CART_example.xml\", max_CART_depth=4, min_obs_per_leaf=2)\n",
        "acc, predicted_values = test_CART(tree_4, dataset_torch)\n",
        "f1 = f1_score(dataset_torch[:,-1], predicted_values) \n",
        "\n",
        "print(f'[GINI] - Accuracy rate=[{acc}], f1_score=[{f1}]')\n",
        "\n",
        "############################### USING ENTROPY ################################\n",
        "USE_GINI = False\n",
        "\n",
        "print('[ENTROPY] - Test CART with max_CART_depth=[3] and min_obs_per_leaf=[2]')\n",
        "tree_3 = train_CART(dataset_torch, name_xml = \"CART_example.xml\", max_CART_depth=3, min_obs_per_leaf=2)\n",
        "acc, predicted_values = test_CART(tree_3, dataset_torch)\n",
        "f1 = f1_score(dataset_torch[:,-1], predicted_values) \n",
        "\n",
        "print(f'[ENTROPY] - Accuracy rate=[{acc}], f1_score=[{f1}]')\n",
        "\n",
        "#########\n",
        "\n",
        "print('[ENTROPY] - Test CART with max_CART_depth=[4] and min_obs_per_leaf=[2]')\n",
        "tree_4 = train_CART(dataset_torch, name_xml = \"CART_example.xml\", max_CART_depth=4, min_obs_per_leaf=2)\n",
        "acc, predicted_values = test_CART(tree_4, dataset_torch)\n",
        "f1 = f1_score(dataset_torch[:,-1], predicted_values) \n",
        "\n",
        "print(f'[ENTROPY] - Accuracy rate=[{acc}], f1_score=[{f1}]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## -2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset_torch = [\n",
            "tensor([[-64, -56, -61,  ..., -82, -81,   1],\n",
            "        [-68, -57, -61,  ..., -85, -85,   1],\n",
            "        [-63, -60, -60,  ..., -85, -84,   1],\n",
            "        ...,\n",
            "        [-62, -59, -46,  ..., -87, -88,   4],\n",
            "        [-62, -58, -52,  ..., -90, -85,   4],\n",
            "        [-59, -50, -45,  ..., -88, -87,   4]], dtype=torch.int32)\n",
            "]\n",
            "[GINI] - Test CART with max_CART_depth=[3] and min_obs_per_leaf=[2]\n",
            "[]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\pavel\\AppData\\Local\\Temp\\ipykernel_31488\\3724860516.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  input = torch.tensor(input)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[GINI] - Accuracy rate=[0.91], f1_score=[0.9105929136276245]\n",
            "[GINI] - Test CART with max_CART_depth=[4] and min_obs_per_leaf=[2]\n",
            "[]\n",
            "[GINI] - Accuracy rate=[0.75], f1_score=[0.8259315490722656]\n",
            "[ENTROPY] - Test CART with max_CART_depth=[3] and min_obs_per_leaf=[2]\n",
            "[]\n",
            "[ENTROPY] - Accuracy rate=[0.93], f1_score=[0.9295657873153687]\n",
            "[ENTROPY] - Test CART with max_CART_depth=[4] and min_obs_per_leaf=[2]\n",
            "[]\n",
            "[ENTROPY] - Accuracy rate=[0.7321428571428571], f1_score=[0.8139196634292603]\n"
          ]
        }
      ],
      "source": [
        "dataset_torch = read_dataset().int()\n",
        "print('dataset_torch = [\\n{}\\n]'.format(dataset_torch))\n",
        "\n",
        "############################### USING GINI ################################\n",
        "USE_GINI = True\n",
        "\n",
        "print('[GINI] - Test CART with max_CART_depth=[3] and min_obs_per_leaf=[2]')\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataset_torch, train_size=0.7)\n",
        "dataset_train = torch.column_stack((X_train, y_train))\n",
        "dataset_test = torch.column_stack((X_test, y_test)) \n",
        "tree_3 = train_CART(dataset_train, name_xml = \"CART_example.xml\", max_CART_depth=3, min_obs_per_leaf=2)\n",
        "acc, predicted_values = test_CART(tree_3, dataset_test)\n",
        "f1 = f1_score(dataset_test[:,-1], predicted_values) \n",
        "\n",
        "print(f'[GINI] - Accuracy rate=[{acc}], f1_score=[{f1}]')\n",
        "\n",
        "#########\n",
        "\n",
        "print('[GINI] - Test CART with max_CART_depth=[4] and min_obs_per_leaf=[2]')\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataset_torch, train_size=0.7)\n",
        "dataset_train = torch.column_stack((X_train, y_train))\n",
        "dataset_test = torch.column_stack((X_test, y_test)) \n",
        "tree_4 = train_CART(dataset_train, name_xml = \"CART_example.xml\", max_CART_depth=4, min_obs_per_leaf=2)\n",
        "acc, predicted_values = test_CART(tree_4, dataset_test)\n",
        "f1 = f1_score(dataset_test[:,-1], predicted_values) \n",
        "\n",
        "print(f'[GINI] - Accuracy rate=[{acc}], f1_score=[{f1}]')\n",
        "\n",
        "############################### USING ENTROPY ################################\n",
        "USE_GINI = False\n",
        "\n",
        "print('[ENTROPY] - Test CART with max_CART_depth=[3] and min_obs_per_leaf=[2]')\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataset_torch, train_size=0.7)\n",
        "dataset_train = torch.column_stack((X_train, y_train))\n",
        "dataset_test = torch.column_stack((X_test, y_test)) \n",
        "tree_3 = train_CART(dataset_train, name_xml = \"CART_example.xml\", max_CART_depth=3, min_obs_per_leaf=2)\n",
        "acc, predicted_values = test_CART(tree_3, dataset_test)\n",
        "f1 = f1_score(dataset_test[:,-1], predicted_values) \n",
        "\n",
        "print(f'[ENTROPY] - Accuracy rate=[{acc}], f1_score=[{f1}]')\n",
        "\n",
        "#########\n",
        "\n",
        "print('[ENTROPY] - Test CART with max_CART_depth=[4] and min_obs_per_leaf=[2]')\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataset_torch, train_size=0.7)\n",
        "dataset_train = torch.column_stack((X_train, y_train))\n",
        "dataset_test = torch.column_stack((X_test, y_test)) \n",
        "tree_4 = train_CART(dataset_train, name_xml = \"CART_example.xml\", max_CART_depth=4, min_obs_per_leaf=2)\n",
        "acc, predicted_values = test_CART(tree_4, dataset_test)\n",
        "f1 = f1_score(dataset_test[:,-1], predicted_values) \n",
        "\n",
        "print(f'[ENTROPY] - Accuracy rate=[{acc}], f1_score=[{f1}]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-07 18:32:11,808] A new study created in RDB with name: my_study2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\pavel\\AppData\\Local\\Temp\\ipykernel_31488\\3724860516.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  input = torch.tensor(input)\n",
            "[I 2024-04-07 18:32:26,546] Trial 0 finished with value: 0.9328571428571428 and parameters: {'max_depth': 3, 'min_obs_per_node': 81}. Best is trial 0 with value: 0.9328571428571428.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-07 18:32:40,419] Trial 1 finished with value: 0.9335714285714286 and parameters: {'max_depth': 2, 'min_obs_per_node': 24}. Best is trial 1 with value: 0.9335714285714286.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-07 18:32:52,985] Trial 2 finished with value: 0.93 and parameters: {'max_depth': 5, 'min_obs_per_node': 13}. Best is trial 1 with value: 0.9335714285714286.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-07 18:33:06,774] Trial 3 finished with value: 0.9292857142857143 and parameters: {'max_depth': 6, 'min_obs_per_node': 54}. Best is trial 1 with value: 0.9335714285714286.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-07 18:33:21,158] Trial 4 finished with value: 0.9278571428571428 and parameters: {'max_depth': 5, 'min_obs_per_node': 70}. Best is trial 1 with value: 0.9335714285714286.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-07 18:33:35,150] Trial 5 finished with value: 0.9357142857142857 and parameters: {'max_depth': 2, 'min_obs_per_node': 81}. Best is trial 5 with value: 0.9357142857142857.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-07 18:33:49,246] Trial 6 finished with value: 0.9342857142857143 and parameters: {'max_depth': 2, 'min_obs_per_node': 83}. Best is trial 5 with value: 0.9357142857142857.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-07 18:34:03,277] Trial 7 finished with value: 0.9307142857142857 and parameters: {'max_depth': 2, 'min_obs_per_node': 93}. Best is trial 5 with value: 0.9357142857142857.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-07 18:34:17,061] Trial 8 finished with value: 0.9307142857142857 and parameters: {'max_depth': 6, 'min_obs_per_node': 33}. Best is trial 5 with value: 0.9357142857142857.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-07 18:34:32,608] Trial 9 finished with value: 0.9335714285714286 and parameters: {'max_depth': 4, 'min_obs_per_node': 95}. Best is trial 5 with value: 0.9357142857142857.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'max_depth': 2, 'min_obs_per_node': 81}\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "\n",
        "def objective(trial):\n",
        "    # hyperparams to optim\n",
        "    max_depth = trial.suggest_int('max_depth', 2, 6)\n",
        "    min_obs_per_node = trial.suggest_int('min_obs_per_node', 1, 100)\n",
        "    \n",
        "    # train cart\n",
        "    X_train, X_test, y_train, y_test = train_test_split(dataset_torch, train_size=0.7)\n",
        "    dataset_train = torch.column_stack((X_train, y_train))\n",
        "    dataset_test = torch.column_stack((X_test, y_test)) \n",
        "    tree = train_CART(dataset_torch,\n",
        "                        name_xml = \"CART_example.xml\",\n",
        "                        max_CART_depth=max_depth,\n",
        "                        min_obs_per_leaf=min_obs_per_node)\n",
        "    acc, predicted_values = test_CART(tree_3, dataset_test)\n",
        "    f1 = f1_score(dataset_test[:,-1], predicted_values)\n",
        "    #return f1\n",
        "    return acc\n",
        "\n",
        "study = optuna.create_study(study_name='my_study2', storage='sqlite:///sqlitedb.db', load_if_exists=True, direction='maximize')\n",
        "study.optimize(objective, n_trials=10)\n",
        "\n",
        "print(study.best_params) "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
